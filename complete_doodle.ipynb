{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from doodle_dataset import DoodleDataset\n",
    "from doodle_parsing_utils import *\n",
    "from doodle_predictor import DoodlePredictor, calculate_loss\n",
    "from doodle_predictor_config import DoodlePredictorConfig\n",
    "from doodle_dataset import encode_stroke_data, decode_stroke_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DoodlePredictorConfig(\"./configs/base_config.json\")\n",
    "doodle_predictor = DoodlePredictor(config).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doodle_predictor.load_state_dict(torch.load(\"./models/bigger_embeds/model_state_dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 54.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = DoodleDataset(\n",
    "    Path(\"./dataset\"),\n",
    "    split=\"test\",\n",
    "    block_size=config.block_size - 1,\n",
    "    device=config.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_doodle(doodle: torch.Tensor, classname_embedding: torch.Tensor, max_strokes=50):\n",
    "    full_doodle = doodle.clone().to(config.device)\n",
    "\n",
    "    num_additional_strokes = 0\n",
    "    doodle_finished = False\n",
    "    while num_additional_strokes <= max_strokes or doodle_finished:\n",
    "        new_stroke = doodle_predictor(\n",
    "            full_doodle[num_additional_strokes:].unsqueeze(0).to(config.device).float(),\n",
    "            classname_embedding.unsqueeze(0).to(config.device).float()\n",
    "        )[0, -1, :]\n",
    "\n",
    "        # Decode the one-hot pen state\n",
    "        new_stroke[2:] = new_stroke[2:] == torch.max(new_stroke[2:])\n",
    "        new_stroke = new_stroke.unsqueeze(0).to(config.device)\n",
    "\n",
    "        full_doodle = torch.cat([full_doodle, new_stroke])\n",
    "\n",
    "        doodle_finished = new_stroke[0, -1].item()\n",
    "        num_additional_strokes += 1\n",
    "    \n",
    "    return full_doodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"136.2\" version=\"1.1\" width=\"303.6\"><defs/><rect fill=\"white\" height=\"136.2\" width=\"303.6\" x=\"0\" y=\"0\"/><path d=\"M25,114.0 m2.4,0.2 l2.0,2.4 4.4,2.6 l4.6,4.8 6.0,5.4 l7.8,7.8 9.4,6.4 l9.4,2.4 10.8,2.6 l12.2,2.2 11.6,0.4 l11.2,-1.4 10.6,-3.0 l16.0,-5.8 16.8,-10.6 l8.8,5.6 13.6,-0.8 l13.2,-2.2 13.8,-3.0 l14.8,-5.0 12.8,-6.0 l14.2,-8.2 10.2,-6.4 l10.4,-7.4 9.2,-7.4 l8.6,-8.2 7.8,-15.6 l6.0,-18.6 4.0,-12.0 l6.4,-4.8 4.6,-5.4 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs, ys, classname_embedding = test_dataset[100]\n",
    "full_doodle = complete_doodle(xs, classname_embedding)\n",
    "decoded_doodle = decode_stroke_data(full_doodle.detach().cpu())\n",
    "draw_strokes(decode_stroke_data(xs), factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"225.297978836298\" version=\"1.1\" width=\"394.0518113851546\"><defs/><rect fill=\"white\" height=\"225.297978836298\" width=\"394.0518113851546\" x=\"0\" y=\"0\"/><path d=\"M25,203.097978836298 m2.4,0.2 l2.0,2.4 4.4,2.6 l4.6,4.8 6.0,5.4 l7.8,7.8 9.4,6.4 l9.4,2.4 10.8,2.6 l12.2,2.2 11.6,0.4 l11.2,-1.4 10.6,-3.0 l16.0,-5.8 16.8,-10.6 l8.8,5.6 13.6,-0.8 l13.2,-2.2 13.8,-3.0 l14.8,-5.0 12.8,-6.0 l14.2,-8.2 10.2,-6.4 l10.4,-7.4 9.2,-7.4 l8.6,-8.2 7.8,-15.6 l6.0,-18.6 4.0,-12.0 l6.4,-4.8 4.6,-5.4 l2.463410758972168,-4.266856288909912 0.9298755645751953,-1.7942675590515136 l1.015661782026291,-0.18642644882202147 2.4051101386547087,0.08408908843994141 l1.887899512052536,0.3753037452697754 1.547690862417221,0.9642011642456054 l1.439019078016281,-0.03765316009521484 2.6407019317150118,-1.2287525177001952 l2.6122547507286074,-2.5677566528320312 2.7452798962593077,-3.353726100921631 l3.145189654827118,-4.635542964935302 3.1961751520633697,-6.256890773773193 l3.3948870956897736,-7.076047325134278 2.9740860760211945,-7.531515789031983 l3.3988851845264434,-7.748401069641114 4.237087661027909,-7.65880269408226 l4.8451722919940945,-7.515322679281235 5.53391335606575,-6.838503164052963 l5.830335718393326,-5.840384668111801 6.446069580316544,-4.927812093496323 l7.004401403665542,-3.7090164124965668 6.3517095148563385,-3.119437497854233 l5.3236636698246,-1.5092982232570649 4.507911831140518,-1.4372711062431336 l3.165039783716202,-0.7372637629508972 1.358841472864151,-0.3917026400566101 l0.051537662744522095,-0.10401276350021363 -1.6337912023067473,-0.007675343751907348 l-2.186296933889389,-0.04123313426971435 -3.345939153432846,0.8059494256973266 l-3.405412030220032,1.1940453767776489 -3.749883222579956,1.2122295662760734 l-4.225663185119629,1.2532208785414696 -4.303878432512283,1.6331268653273583 l-5.527049094438553,1.7322862073779106 -6.155430680513382,2.6186771795153616 l-6.209573662281036,2.765298216044903 -7.2011265873909,3.2179926320910455 l-6.74581218957901,3.7409341260790825 -7.272225391864777,3.452956812083721 l-7.407752645015717,4.513856832683087 -6.46922515630722,3.5127759382128714 l-6.1999535202980045,3.478042076528072 -6.281412023305893,3.6780107006430627 l-6.1629536807537075,3.791032074391842 -5.551159638166427,3.2190846905112265 l-5.0618715465068815,2.4314970478415487 -4.4182675063610075,2.0928462490439417 l-3.4100538909435274,1.364295242726803 -2.5207466781139374,0.6942443355917931 l-1.3843638122081756,-0.046244002878665924 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_strokes(decoded_doodle, factor=5)\n",
    "\n",
    "# NOTE: WE REALLLLLY NEED TO INCREASE THE WEIGHTING ON THE FIRST TWO TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(full_doodle[1:32].unsqueeze(0).to(config.device), ys.unsqueeze(0).to(config.device), config.position_loss_coeff, config.pen_state_loss_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([31, 5]), torch.Size([31, 5]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_doodle[1:32].shape, ys.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DoodleGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
